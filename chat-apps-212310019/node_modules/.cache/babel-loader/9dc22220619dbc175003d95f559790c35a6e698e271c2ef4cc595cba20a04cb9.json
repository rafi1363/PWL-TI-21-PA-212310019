{"ast":null,"code":"/*eslint no-useless-escape: \"off\"*/\n\n/**\n * Remove special characters and return an array of tokens (words).\n * @param  {string} input Input string\n * @return {array}        Array of tokens\n */\nmodule.exports = function (input) {\n  return input.toLowerCase().replace(/\\n/g, ' ').replace(/[.,\\/#!?$%\\^&\\*;:{}=_`\\\"~()]/g, ' ').replace(/\\s\\s+/g, ' ').trim().split(' ');\n};","map":{"version":3,"names":["module","exports","input","toLowerCase","replace","trim","split"],"sources":["D:/Document/PWL/Materi/main pemograman-web-lanjut-212310006/node_modules/sentiment/lib/tokenize.js"],"sourcesContent":["/*eslint no-useless-escape: \"off\"*/\n\n/**\n * Remove special characters and return an array of tokens (words).\n * @param  {string} input Input string\n * @return {array}        Array of tokens\n */\nmodule.exports = function(input) {\n    return input\n        .toLowerCase()\n        .replace(/\\n/g, ' ')\n        .replace(/[.,\\/#!?$%\\^&\\*;:{}=_`\\\"~()]/g, ' ')\n        .replace(/\\s\\s+/g, ' ')\n        .trim()\n        .split(' ');\n};\n"],"mappings":"AAAA;;AAEA;AACA;AACA;AACA;AACA;AACAA,MAAM,CAACC,OAAO,GAAG,UAASC,KAAK,EAAE;EAC7B,OAAOA,KAAK,CACPC,WAAW,CAAC,CAAC,CACbC,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC,CACnBA,OAAO,CAAC,+BAA+B,EAAE,GAAG,CAAC,CAC7CA,OAAO,CAAC,QAAQ,EAAE,GAAG,CAAC,CACtBC,IAAI,CAAC,CAAC,CACNC,KAAK,CAAC,GAAG,CAAC;AACnB,CAAC","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}